{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split.ipynb\n",
    "\n",
    "Splits up the tilt-schema json into its constituent parts. \n",
    "It further moves the properties section of the tilt into another subdirectory and splits it again. \n",
    "\n",
    "You should only execute the cells in this notebook if you want to definitely overwrite the files that are in the tilt_schema directory. \n",
    "\n",
    "These files are used by the GitHub action in main.yaml to reconstruct the tilt. \n",
    "\n",
    "This decomposition was made for easier readability and tractability of the tilt-schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "\n",
    "# adopted from chatGPT\n",
    "\n",
    "def split_json(filepath_og):\n",
    "    # Open the original JSON file\n",
    "    with open(filepath_og, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Iterate over the top-level keys in the JSON object\n",
    "    for i, key in enumerate(data.keys()):\n",
    "        # Create a new dictionary containing only the data for this key\n",
    "        section = { key: data[key] }\n",
    "\n",
    "        # Write the section to a new JSON file\n",
    "        with open(f'{i:02d}_{key}.json', 'w') as f:\n",
    "            json.dump(section, f)\n",
    "\n",
    "    return data.keys()\n",
    "\n",
    "split_json('../tilt-schema.json')\n",
    "\n",
    "\n",
    "# Open the original JSON file\n",
    "with open('06_properties.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Iterate over the top-level keys in the JSON object\n",
    "for i, key in enumerate(data['properties'].keys()):\n",
    "    # Create a new dictionary containing only the data for this key\n",
    "    section = { key: data['properties'][key] }\n",
    "\n",
    "    # Write the section to a new JSON file\n",
    "    os.makedirs(os.path.dirname(f'properties/{i:02d}_{key}.json'), exist_ok=True)\n",
    "    with open(f'properties/{i:02d}_{key}.json', 'w') as f:\n",
    "        json.dump(section, f)\n",
    "\n",
    "os.remove(\"06_properties.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct():\n",
    "\n",
    "    \"\"\"\n",
    "    func:   Constructs the tilt-schema out of a number of constituent parts.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    properties_sections = sorted(glob.glob('properties/*.json'))\n",
    "\n",
    "    \n",
    "    print(properties_sections)\n",
    "    \n",
    "    # Update the properties file with the underlying values \n",
    "    # Note: presupposes that all changes to the properties have been made in the properties-folder\n",
    "    data_props = []\n",
    "    for subfile in properties_sections:\n",
    "\n",
    "        with open(subfile, 'r') as sf:\n",
    "            data_props.append(json.load(sf))\n",
    "            \n",
    "    combo_props = {}\n",
    "    for item in data_props:\n",
    "        combo_props.update(item)\n",
    "        \n",
    "    # Write the combined data to a the properties file\n",
    "    with open('06_properties.json', 'w') as f:\n",
    "        json.dump({'properties':combo_props}, f)\n",
    "    \n",
    "    meta_sections = sorted(glob.glob(\"*.json\"))\n",
    "    print(meta_sections)\n",
    "\n",
    "\n",
    "    # Create an empty list to hold the data from each file\n",
    "    data = []\n",
    "\n",
    "    # Iterate over each JSON file and load its contents into the data list\n",
    "    for file in meta_sections:\n",
    "        with open(file, 'r') as f:\n",
    "            data.append(json.load(f))\n",
    "\n",
    "    # Combine all the data into a single dictionary\n",
    "    combined_data = {}\n",
    "    for item in data:\n",
    "        combined_data.update(item)\n",
    "\n",
    "    \n",
    "    # Write the combined data to a new JSON file\n",
    "    with open('../combined.json', 'w') as f:\n",
    "        json.dump(combined_data, f)\n",
    "        print('successfully created new json')\n",
    "\n",
    "    os.remove(\"06_properties.json\")\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['properties/00_meta.json', 'properties/01_controller.json', 'properties/02_dataProtectionOfficer.json', 'properties/03_dataDisclosed.json', 'properties/04_thirdCountryTransfers.json', 'properties/05_accessAndDataPortability.json', 'properties/06_sources.json', 'properties/07_rightToInformation.json', 'properties/08_rightToRectificationOrDeletion.json', 'properties/09_rightToDataPortability.json', 'properties/10_rightToWithdrawConsent.json', 'properties/11_rightToComplain.json', 'properties/12_automatedDecisionMaking.json', 'properties/13_changesOfPurpose.json']\n",
      "['00_$schema.json', '01_$id.json', '02_type.json', '03_title.json', '04_description.json', '05_examples.json', '06_properties.json', '07_required.json']\n",
      "successfully created new json\n"
     ]
    }
   ],
   "source": [
    "reconstruct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No differences found between the two files.\n"
     ]
    }
   ],
   "source": [
    "# Load the data from the first file\n",
    "with open('../tilt-schema.json', 'r') as f:\n",
    "    data1 = json.load(f)\n",
    "\n",
    "# Load the data from the second file\n",
    "with open('../combined.json', 'r') as f:\n",
    "    data2 = json.load(f)\n",
    "\n",
    "# Compare the two data sets and print out any differences\n",
    "if data1 != data2:\n",
    "    print(\"Differences found between the two files:\")\n",
    "    for key in set(data1.keys()).union(set(data2.keys())):\n",
    "        if data1.get(key) != data2.get(key):\n",
    "            print(f\"Key '{key}' differs between the files:\")\n",
    "            print(f\"File 1: {data1.get(key)}\")\n",
    "            print(f\"File 2: {data2.get(key)}\")\n",
    "else:\n",
    "    print(\"No differences found between the two files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63466\n",
      "63466\n"
     ]
    }
   ],
   "source": [
    "print(len(str(data1)))\n",
    "print(len(str(data2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
